大数据基础导论：
1. 什么是大数据 ???
	大数据:  指的是无法在一定的时间内, 通过常规的手段捕获和处理数据的集合
		
2008年国外有了开源的大数据框架(hadoop), 中国大约2013年开始的
		阿里大约是在2008年开始(云梯项目)
常规的手段 :  最早将数据存储在关系型的数据库中 , 数据分析都是建立在关系型数据库上面的
		

数据存储单位:  byte kb mb gb tb  pb  最大 DB


2. 大数据的特点:
	2.1) 大量:  
	2.2) 高速 :
	2.3) 多样化:  结构化的数据, 半结构化数据, 非结构化数据
	2.4)  低价值密度:  数据量越大, 价值越低
	
结构化的数据(业务数据):  有固定的字段, 字段的类型都是统一的, 数据库中表数据
半结构化数据: 有一定的结构, 字段的个数不同, json  xml
	[{name:"张三",age:12},{"name":"张三"}]
非结构化数据:  完全没有任何结构   图片, 视频, word  pdf

3. 大数据的作用 :  
	3.1) O2O:线上线下:  线下的实体店选址,
	3.2) 旅游行业:  山西大同
	3.3) 保险行业: 
	3.4) 零售:  尿布+啤酒
	总结: 各个行业当中都要使用大数据来进行数据的分析处理

4. 发展前景:
	1) 国家政策:  学校科目开设
	2) 人才缺口
-------------------------------------------------------------------------------
5) 服务器的基本介绍: 理解就是一台电脑, 只不过配置要比普通要高
		在实际工作当中, 如果是中小型的公司, 一般使用云上主机

	服务器的网卡一般有二个 : 一个网络用于内网, 一个网卡外网

6) 磁盘的接口:   sata接口 
	
	机械磁盘传输的速率:  转数有关
		sata盘: 7200转
		sas盘:  10000转 到 15000转
	服务器一般如何选择磁盘:
		1) 速度快 : 
		2) 可靠性要高:  7*24小时   不容易出现损坏的问题
		3) 使用sata接口和 sas接口
		4) 支持热插拔
7) 服务器的网卡 :  
	对数据编码和解码操作, 每一个网卡都有一个mac地址, 全世界唯一的

8) 交换机:  一般是用来组建局域网络的
	主要的作用: 数据的分发与传输的
	
9) IDC数据中心:  提高用户的访问效率
		作用: 提供托管服务
		
	三大运营商都有IDC的数据中心(大大的机房)
	
10) 磁盘的存储方案:  如何来扩大磁盘存储
	磁盘 + 磁盘的过程
	
	raid :独立磁盘冗余阵列
	
	raid 0  :   1+1 =2   将二个磁盘组件在一起, 如果都是1tb的磁盘, 组建在一起就是2Tb
		不提供任何的冗余
	raid 1  :   1+1 = 1  将二个磁盘组件在一起, 如果都是1tb的磁盘,组建在一起依然还1Tb
	 
	比如, 现在有2Tb的数据, 使用raid0 可以将其存储, 但是如果使用raid1 只能存储1tB, 另外1Tb提供冗余策略
		相当于将数据存储了二份
	
	
	从raid  2 ~  raid 6 : 理解为是raid0 和 raid 1 中间值
		采用校验机制
	
	raid  6 
	
冗余: 重复东西搞了多次
阵列：将多个磁盘组建在一起

在实际工作当中一般都是采用: 组合的方式:  raid01  raid 10  raid 00方案

  
网络拓扑图 : 使用交换机来构建网络拓扑结构

--------------------------------------------------------------
大数据的环境统一:
1) 准备三台centos 6.9  64位的虚拟机, 三台必须联网
2) 三台服务器防火墙必须是永久关闭: 
		chkconfig  iptables off    永久关闭, 下一次启动生效
		service iptables  stop    一次性关闭, 下一次启动无效, 当前有效
3) 关闭三台服务器的深层防火墙: selinux(修改配置文件)

4) 三台服务器更改主机名:     ----注意此处和之前是不一样
	ip从小到大, 依次的主机名  node01.hadoop.com  , node02.hadoop.com,node03.hadoop.com
		如何修改主机名:  vi  /etc/sysconfig/network

5) 修改主机名和ip的映射关系:  hosts文件  ----注意此处和之前是不一样
	修改的方案: vi /etc/hosts
		修改的案例内容:
			
			192.168.72.141 node01.hadoop.com  node01
			192.168.72.142 node02.hadoop.com  node02
			192.168.72.143 node03.hadoop.com  node03
6) 修改后, 对三台服务器进行重启:  reboot  
7) 进行ssh免密配置: 需要再次验证, 以保证ssh配置成功的(每一台都要验证)
		使用:  ssh  主机名  
8) 时钟同步 :  推荐使用第一种(简单):
	使用date命令验证


9) 三台服务器必须安装jdk1.8 
		使用: java -version

		
细心细心加细心


作业:
	大数据的环境的统一：安装三台Linux服务器并配置免密登录
