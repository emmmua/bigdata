课前回顾:
1) MapReduce的工作机制:
	map阶段工作机制
	reduce端工作机制

	shuffle的整个过程

2) 数据的压缩:  map阶段的结果文件, reduce输出的结果文件	
	snappy  
	选择压缩方案的原则:  客观压缩比  客观解压缩的速率
	一共有五个压缩的配置:  
	
3) MapReduce的join的实现:
	map的端的join :  适合于 小表 和 大表 join情况, 一般将小表放置到内存当中
	reduce端的join:  适合于 大表join大表的情况    数据倾斜的问题(注意)


4) 求共同好友: 

5) 求 某一个单词在某一个文件中出现了多少次
6) 自定义输入  : 



今日内容:
1) 自定义的输出 (重点搞定)
2) MapReduce中分组(如何来自定义分组)  (重点搞定)
3) MapReduce的多Job串联 :  了解一下
4) MapReduce的	参数优化:  知道就行
5) yarn的架构 和原理 :
		yarn的提交job任务的流程 (重点的理解)
6) RM  和 NM 的功能介绍  (了解即可)
7) yarn的 appMaster :  了解即可
8) yarn的资源的调用 :  理解三种调度方案
9) 多租户的配置实现资源的隔离  (会配置)
10)  hadoop的高可用  (会配置)



1) 如何自定义的输出 :
	需求 :  有一份文件, 商城网站对, 用户对某一个商品的评价信息(差评  好评)
			请将这个文件中 好评 和 其他的评论 分来成两个文件, 而且这两个文件要在不同的文件夹下面

	需求对输出类, 进行自定义操作, 让其支持输出两个文件夹 :  抄
		1) 创建一个类, 继承FileOutputFormat <k3,v3>
		2) 重写 方法:  getRecordWriter() ;  如何来获取一个 RecordWriter
			2.1) 自定义一个 RecordWriter ： 如何往外写的过程
					创建一个类型, 继承 RecordWriter<k3,v3>
					重写方法:  write()    close()
		
2) MapReduce中分组:  将相同的key的value值进行合并为一个集合
	分区:  将一大坨的数据, 分为多少区, 每个区里面可能会有很多不同key, 同一个key,肯定是在同一个reduce中
	分组:  在同一个reduce(在同一个分区)上面, 对相同key的进行合并的过程
	
	需求 :  有一个订单数据, 要求对订单数据, 按照订单进行分组排序, 求 topn
	
		订单id        商品id       成交金额
	Order_0000001      Pdt_01       222.8
	Order_0000001      Pdt_05       25.8
	Order_0000002      Pdt_03       522.8


	先求一个topn : SQL  不是很容易实现的
		select  * from  orders group by  orderid   order by  price  desc  ;
		
	MapReduce写  :  

	在对MapReduce进行高级编程: 可以对 MapReduce中八大步骤, 都可能进行自定义操作, 实现更加复杂的MapReduce计算任务

		
	自定义分组的步骤":
		1) 继承WritableComparator类
		2) 重写 compare(WritableComparable k2_1, WritableComparable k2_2), 分组的规则
		3) 编写一个构造 :  指定排序的k2 的类型 已经是否需要进行创建
				super(Orders.class,true);


3) 多job的串联:  将多个MapReduce的任务给串联在一起 , 当执行完第一个任务后, 执行第二个任务, 依次类推
	适合于:  多个任务, 某个任务要用到上一个任务的结果的情况:  共同好友

	azkaban  oozie   任务调度框架

4) MapReduce的参数的优化: 
	资源 :  内存  CPU 
	环形缓冲区设置大小:  mapreduce.task.io.sort.mb   100   默认100M
	yarn中设置: yarn.nodemanager.resource.memory-mb  默认是 8GB
		在生产环境下, 需要将其设置为和服务器的内存是一致的, 或者小于服务器的内存

	作业的信息的配置:  mapreduce.task.timeout  默认  10分钟, 单位毫秒
		程序在没有读取和没有输出的时候(程序在内部可能是卡住了, 也可能计算任务太庞大), 允许多长时间的卡住
		
		
	 效率和稳定性相关参数:  MapReduce的推测执行:
			比如: map的推测执行, 当mapTask在运行的时候, 如果这个mapTask运行过程中卡住了,  对应yarn来将, 认为这个运行效率可以比较慢 ,
					再次启动一个同样的mapTask的任务, 两个mapTask一起跑, 那个maPtask先运行完, 就使用那个maptask的结果


5) yarn :   统一的资源调度框架 
	在2.x后面出现的, 主要有二大角色:  resourceManager(资源的分配)  和 nodeManager(执行任务)
	在1.x 如何计算MapReduce:  jobTracker(资源的分配 和任务的分配) TaskTracker (执行任务) 

	hdfs:  
		datanode: 出磁盘
	yarn:
		nodeManager : 出 内存 和 CPU

	实际生产环境下, 都是将datanode 和 nodeManager启动在一台机子




7) yarn集群的资源的调度方案:  三种

	资源调度器:  如何合理将资源进行分配
	 
	FIFO : 先进先出的调度器   ---一般没人使用
		谁先来的, 让谁使用所有的资源运行, 后来的等待前面的任务运行完成
			例如:  第一个任务, 运行 2小时   第二个任务  10分钟
		
	capacity scheduler  : 容器 调度器  
			提供了多个队列, 为每一个队列都提前的分配了资源占用比, 每一个队列都可以设置最小资源和最大资源
			第一个队列:  30%   ---主要运行小任务
			第二个队列:  50%   ---主要运行大的任务
			第三个队列:  20%   -----
		并行的运行多个任务, 如果某一个将某一个队列当中所有的资源全部占用后, 依然不够
			支持可以将其他队列的空闲资源给予这个队列, 使用, 但是如果其他的队列突然又有了
				任务, 要求另一个队列归还资源(不会强制归还)
		弊端:  会造成一定的资源浪费, 同时,对于大的任务的运行, 时间效率比较长
		
	fair scheduler : 公平调度器  
		提供了多个队列, 为每一个队列都提前的分配了资源占用比
		第一个队列:  30%   ---主要运行小任务
		第二个队列:  50%   ---主要运行大的任务
		第三个队列:  20%   -----
		
		并行的运行多个任务, 果某一个将某一个队列当中所有的资源全部占用后, 依然不够， 会将其所有人资源全部获取过来
		
		当第一个任务来的时候 会占用全部的资源,当第二个任务来的时候, 第一个任务会分配出来一点资源给第二个任务使用
			尽可能的保证所有的任务都能够分配到资源来运行任务(保证公平)
		
		支持抢占模式 : 
			当某一个任务运行的时候,将其它队列的资源拿走后, 如果其他的队列要运行, 会找这个任务, 获取资源, 如果任务
				在一定的时间内, 没有给资源, 直接强制将任务杀死, 把资源获取到
		
	

	在apache的hadoop版本中, 默认使用调度器:   capacity scheduler  : 容器 调度器
	在CDH的hadoop版本中, 默认使用调度器 :  fair scheduler : 公平调度器

yarn的多租户的配置 :
	有多个用户来使用yarn集群, 有多个用户共用yarn集群资源

	假设一个用户来使用yarn集群, 将yarn集群的资源, 全部占用(100%), 当第二个用户来的时候, 发现没有任何资源
	
	解决方案: 尝试让某一个用户只能使用整个集群资源的30%, 剩余资源给予其他的用户使用, 这样保证多个用户都可以
		使用yarn集群, 并且都可以得到自己的资源
	
	在进行配置前, 建议对linux进行快照拍摄, 以方便后期恢复原状 :
	
	
	
hadoop的高可用:  
	HA(High Available), 高可用，是保证业务连续性的有效解决方案  保证服务器 7*24不宕机
	备份节点的越多, 宕机风险越低, 但是造成更多的资源的浪费
	
	在hadoop 对应namenode  和  resourceManager 最多只允许有二个节点
	
	namenode的高可用:  
		在2.x的时候, 就已经有了高可用
	
	yarn的高可用:
		2.4版本后, 提供的高可用
	


